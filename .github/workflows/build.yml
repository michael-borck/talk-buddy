name: Build and Release

on:
  push:
    tags:
      - 'v*'

permissions:
  contents: write

jobs:
  build:
    runs-on: ${{ matrix.os }}
    
    strategy:
      matrix:
        os: [macos-latest, ubuntu-latest, windows-latest]
        include:
          - os: macos-latest
            platform: mac
          - os: ubuntu-latest
            platform: linux
          - os: windows-latest
            platform: win

    steps:
      - name: Check out Git repository
        uses: actions/checkout@v4

      - name: Install Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install dependencies
        run: npm ci

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Build embedded server (Unix)
        if: matrix.os != 'windows-latest'
        run: |
          cd embedded-server
          python -m pip install --upgrade pip
          # Install lightweight pywhispercpp instead of openai-whisper (saves ~1.6GB)
          pip install piper-tts flask flask-cors pywhispercpp pyinstaller
          
          # Download Piper voice models
          mkdir -p models
          curl -L -o models/en_GB-alan-low.onnx https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_GB/alan/low/en_GB-alan-low.onnx
          curl -L -o models/en_GB-alan-low.onnx.json https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_GB/alan/low/en_GB-alan-low.onnx.json
          curl -L -o models/en_US-amy-low.onnx https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_US/amy/low/en_US-amy-low.onnx
          curl -L -o models/en_US-amy-low.onnx.json https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_US/amy/low/en_US-amy-low.onnx.json
          
          # Download whisper-tiny model for pywhispercpp (will be included in build)
          mkdir -p whisper-models
          curl -L -o whisper-models/ggml-tiny.bin https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin
          
          # Create PyInstaller executable with optimizations
          pyinstaller --onefile \
            --add-data "models:models" \
            --add-data "whisper-models:whisper-models" \
            --exclude-module torch \
            --exclude-module tensorflow \
            --exclude-module PIL \
            --exclude-module matplotlib \
            --exclude-module pandas \
            --exclude-module scipy \
            --strip \
            --name embedded-server server.py
          
          # Copy executable to main project for Electron to bundle
          mkdir -p ../dist-server
          cp dist/embedded-server* ../dist-server/

      - name: Build embedded server (Windows)
        if: matrix.os == 'windows-latest'
        run: |
          cd embedded-server
          python -m pip install --upgrade pip
          pip install piper-tts flask flask-cors pywhispercpp pyinstaller
          
          mkdir models
          curl -L -o models/en_GB-alan-low.onnx https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_GB/alan/low/en_GB-alan-low.onnx
          curl -L -o models/en_GB-alan-low.onnx.json https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_GB/alan/low/en_GB-alan-low.onnx.json
          curl -L -o models/en_US-amy-low.onnx https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_US/amy/low/en_US-amy-low.onnx
          curl -L -o models/en_US-amy-low.onnx.json https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_US/amy/low/en_US-amy-low.onnx.json
          
          mkdir whisper-models
          curl -L -o whisper-models/ggml-tiny.bin https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin
          
          pyinstaller --onefile --add-data "models;models" --add-data "whisper-models;whisper-models" --exclude-module torch --exclude-module tensorflow --exclude-module PIL --exclude-module matplotlib --exclude-module pandas --exclude-module scipy --name embedded-server server.py
          
          mkdir ..\dist-server
          copy dist\embedded-server* ..\dist-server\

      - name: Build Vite app
        run: npm run build

      - name: Build Electron app (Windows)
        if: matrix.os == 'windows-latest'
        run: npm run electron:build -- --win
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Build Electron app (macOS)
        if: matrix.os == 'macos-latest'
        run: npm run electron:build -- --mac
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          CSC_IDENTITY_AUTO_DISCOVERY: false

      - name: Free disk space (Linux)
        if: matrix.os == 'ubuntu-latest'
        run: |
          echo "Available space before cleanup:"
          df -h
          # Remove unnecessary packages and files to free space
          sudo apt-get clean
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          docker system prune -af
          # Clean up embedded server build artifacts (keeping dist-server for Electron)
          rm -rf embedded-server/build embedded-server/__pycache__
          find embedded-server -name "*.pyc" -delete 2>/dev/null || true
          # Clean up large Python cache files
          pip cache purge 2>/dev/null || true
          echo "Available space after cleanup:"
          df -h

      - name: Build Electron app (Linux)
        if: matrix.os == 'ubuntu-latest'
        run: npm run electron:build -- --linux
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.platform }}-distributables
          path: |
            dist/*.exe
            dist/*.msi
            dist/*.dmg
            dist/*.pkg
            dist/*.AppImage
            dist/*.deb
            dist/*.snap
            dist/*.yml
            dist/*.yaml

  release:
    needs: build
    runs-on: ubuntu-latest
    
    steps:
      - name: Check out Git repository
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: release-artifacts

      - name: Create Release
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh release create "${{ github.ref_name }}" \
            --title "Talk Buddy ${{ github.ref_name }}" \
            --notes "## Talk Buddy Release ${{ github.ref_name }}
            
            ### Downloads
            
            #### Windows
            - \`Talk Buddy-Setup-*.exe\` - Windows installer
            
            #### macOS
            - \`Talk Buddy-*.dmg\` - macOS installer
            
            #### Linux
            - \`Talk Buddy-*.AppImage\` - Universal Linux app
            - \`Talk Buddy-*.deb\` - Debian/Ubuntu package
            
            ### Installation Instructions
            
            **Windows:** Download and run the .exe installer
            
            **macOS:** Download the .dmg file, open it, and drag Talk Buddy to Applications
            
            **Linux:** 
            - AppImage: Make executable with \`chmod +x\` and run
            - DEB: Install with \`sudo dpkg -i Talk\ Buddy-*.deb\`
            
            ### Requirements
            - Microphone access for speech recognition
            - Internet connection for AI services
            - Speaches server for text-to-speech (configurable)
            - Ollama or OpenAI API for conversation AI (configurable)
            
            ### What's New
            - Collapsible dark-themed sidebar
            - Resume in-progress sessions
            - Improved TTS with gender-specific models
            - Better error handling for STT/TTS services
            - Configurable speech speed
            - Many UI/UX improvements"

      - name: Upload Release Assets
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Upload all artifacts to the release
          find release-artifacts -type f \( -name "*.exe" -o -name "*.dmg" -o -name "*.AppImage" -o -name "*.deb" -o -name "*.zip" \) -exec gh release upload "${{ github.ref_name }}" {} \;